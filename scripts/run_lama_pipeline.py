#!/usr/bin/env python
"""
–ó–∞–ø—É—Å–∫–∞–µ—Ç LightAutoML –Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö CSV —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.

–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç Titanic, –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π DataAgent –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –≤
`data/processed/<dataset_name>/LAMA`. –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ç–∞–±–ª–∏—á–Ω—ã–π –ø—Ä–µ—Å–µ—Ç LAMA,
–æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ train+val –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —Å –º–µ—Ç—Ä–∏–∫–æ–π ROC-AUC.
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

import pandas as pd
from sklearn.metrics import roc_auc_score

try:
    from lightautoml.utils import create_leaderboard
except ImportError:
    create_leaderboard = None

try:
    from lightautoml.automl.presets.tabular_presets import TabularAutoML
    from lightautoml.tasks import Task
except ImportError as exc:
    raise SystemExit(
        "LightAutoML –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–∏–ª–∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–∫–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω) "
        "–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—É—Å–∫: `pip install lightautoml`."
    ) from exc


PROJECT_ROOT = Path(__file__).resolve().parents[1]
DEFAULT_DATASET = "titanic"
TARGET_COLUMN = "Survived"


def load_dataset(dataset_name: str) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """–ß–∏—Ç–∞–µ—Ç train/val/test CSV –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞."""
    dataset_dir = PROJECT_ROOT / "data" / "processed" / dataset_name / "LAMA"
    if not dataset_dir.exists():
        raise FileNotFoundError(
            f"–ö–∞—Ç–∞–ª–æ–≥ {dataset_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–Ω–∞—á–∞–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ DataAgent."
        )

    train_path = dataset_dir / f"{dataset_name}_train.csv"
    val_path = dataset_dir / f"{dataset_name}_val.csv"
    test_path = dataset_dir / f"{dataset_name}_test.csv"

    for path in (train_path, val_path, test_path):
        if not path.exists():
            raise FileNotFoundError(f"–û–∂–∏–¥–∞–ª—Å—è —Ñ–∞–π–ª {path}, –Ω–æ –æ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")

    train_df = pd.read_csv(train_path)
    val_df = pd.read_csv(val_path)
    test_df = pd.read_csv(test_path)
    return train_df, val_df, test_df


def train_and_evaluate(
    train_df: pd.DataFrame,
    val_df: pd.DataFrame,
    test_df: pd.DataFrame,
    target_column: str = TARGET_COLUMN,
    timeout: int | None = 600,
) -> None:
    """–û–±—É—á–∞–µ—Ç TabularAutoML –∏ –ø–µ—á–∞—Ç–∞–µ—Ç ROC-AUC –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ."""
    train_full = pd.concat([train_df, val_df], ignore_index=True)

    if target_column not in train_full.columns:
        raise KeyError(f"–°—Ç–æ–ª–±–µ—Ü —Ç–∞—Ä–≥–µ—Ç–∞ `{target_column}` –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–∞–Ω–Ω—ã—Ö.")

    task = Task("binary")
    automl = TabularAutoML(task=task, timeout=timeout)

    print("‚ñ∂Ô∏è  –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ LightAutoML...")
    oof_predictions = automl.fit_predict(train_full, roles={"target": target_column})

    leaderboard = create_leaderboard(oof_predictions) if create_leaderboard else None
    if leaderboard is not None and not leaderboard.empty:
        best_model = leaderboard.iloc[0]
        try:
            score_value = float(best_model.get("score", float("nan")))
            print(
                f"üèÜ –õ—É—á—à–∏–π –º–æ–¥–µ–ª—å–Ω—ã–π –±–ª–µ–Ω–¥: {best_model.get('model', 'unknown')} "
                f"(score={score_value:.4f})."
            )
        except (TypeError, ValueError):
            print(f"üèÜ –õ—É—á—à–∏–π –º–æ–¥–µ–ª—å–Ω—ã–π –±–ª–µ–Ω–¥: {best_model.get('model', 'unknown')}.")
        print("–¢–æ–ø-5 –º–æ–¥–µ–ª–µ–π –ø–æ –≤–µ—Ä—Å–∏–∏ LightAutoML:")
        print(leaderboard.head())

    features_test = test_df.drop(columns=[target_column])
    target_test = test_df[target_column]

    predictions = automl.predict(features_test).data[:, 0]
    score = roc_auc_score(target_test, predictions)
    print(f"‚úÖ –ì–æ—Ç–æ–≤–æ. ROC-AUC –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {score:.4f}")


def parse_args(argv: list[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="–ó–∞–ø—É—Å–∫ LightAutoML –Ω–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
    )
    parser.add_argument(
        "--dataset",
        default=DEFAULT_DATASET,
        help=f"–ò–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ `data/processed` (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é {DEFAULT_DATASET}).",
    )
    parser.add_argument(
        "--timeout",
        type=int,
        default=600,
        help="–¢–∞–π–º–∞—É—Ç –æ–±—É—á–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö. 0 –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—ã–∫–ª—é—á–∞–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ.",
    )
    return parser.parse_args(argv)


def main(argv: list[str] | None = None) -> None:
    args = parse_args(argv or sys.argv[1:])
    timeout = args.timeout if args.timeout and args.timeout > 0 else None

    train_df, val_df, test_df = load_dataset(args.dataset)
    train_and_evaluate(train_df, val_df, test_df, timeout=timeout)


if __name__ == "__main__":
    main()

